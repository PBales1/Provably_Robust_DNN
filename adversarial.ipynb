{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tVYA302cLyfP"
   },
   "source": [
    "# Provable Robustness for Deep Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3LbEBZGKLyfZ"
   },
   "source": [
    "In this notebook, we will implement the robustness certificate that we derived in the PDF. That is, we will first define and train a three-layer neural classifier; then, we will calculate its dual, and using this, check whether the classifier is dual at given input points.\n",
    "\n",
    "**Your task is to fill in any sections labeled TODO in the code and answer the bolded questions.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GJMgQYklLyfd"
   },
   "source": [
    "We are using torch here; for our purposes, we can think of torch as essentially numpy with GPU support and and automatic differentiation. That is, for any function we compute, torch automatically keeps track of the function's gradient with respect to inputs; this will make gradient descent much easier to implement. \n",
    "\n",
    "The primary object you will need to manipulate here is `torch.Tensor`, which can be thought of as equivalent to  `np.array`. Indexing, splicing, multiplication, etc. will work like you would expect them to in numpy.\n",
    "\n",
    "Also, most of the numpy functions you are used to are present in torch, with the same name. E.g:\n",
    "* `np.max(input, axis)` --> `torch.max(input, dim)` (Note that `torch.max` actually returns a tuple of the max and argmax).\n",
    "* `np.zeros` --> `torch.zeros`\n",
    "* `np.eye` --> `torch.eye`\n",
    "* `np.linalg.norm(x, ord, axis)` --> `torch.norm(input, p, dim)`\n",
    "\n",
    "For more information, refer to the [torch documentation](https://pytorch.org/docs/stable/torch.html) or the [torch tutorials](https://pytorch.org/tutorials/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L3ChNfnaLBbw"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PczgocJtLBb0"
   },
   "source": [
    "Here, we import the relevant libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y3oepvCSLyfi"
   },
   "outputs": [],
   "source": [
    "# !{sys.executable} -m pip install torch\n",
    "# !{sys.executable} -m pip install torchvision\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DPbnELbsLBcM"
   },
   "source": [
    "This line tells torch to use the GPU if available, and otherwise the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "hBpT1WebQ394",
    "outputId": "4316775c-297a-4541-c43c-89efc5bcb9c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "awgBbuiRLyf0"
   },
   "source": [
    "Here, we load in the MNIST dataset. The inputs are $28\\times 28$ images of handwritten digits, while the labels are the corresponding digit. Note that we split the data between a training set and a test set. In order to have an unbiased estimate of the classifier's performance, we must train the model only on the training set (**never the test set**), then test its accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334,
     "referenced_widgets": [
      "c33f5dd2c1f443f1b771f0c46054eebf",
      "9601fc4be35543a784d4231a2de31edb",
      "8c6d1f7d352a4c089e4ae601a73c1068",
      "3ce16927200e4dfbba645b52ede3be15",
      "8a08a24593a2422985302484dc4594d1",
      "410b4797b4eb474185b6e9e8768efe90",
      "7f3be4825b3942bfbd15404ae2826968",
      "51fab2724f5240f2a197da36bfb5d37f",
      "1e0fc65863e247bba684aa570176e47e",
      "0ffb65b8fcd64017a1575ef5c6fb6783",
      "9b0d7cc1d4a84b32ad704d0f92aaf7c2",
      "359ca0eaed76461b8920085a62f10151",
      "0d2ab5e4e4634c2d84445dcb59e63093",
      "c75be203b59b4c599fd51b44b5359236",
      "7cb630c6d3784c0ba705b39311a36690",
      "080f0e9e20374c8b9d0772c207d40204",
      "443bc19134b346e282b58b81de72ee9b",
      "be2ab404919947b6bec6e47d8ef2293e",
      "d51c1aaaee7e40eb9a6946ee964f26db",
      "75a9df895ea94bb787ead957f9b540c9",
      "40781e910ad14961b70299654d08af57",
      "48f34dff73514ae58be4a78b897605de",
      "73155d071971464cac0ed23138cde635",
      "ad74039e867d489fbcc6c9d8ff34706c",
      "bde4879694234dc087cc6ef3a8f999e4",
      "86cdc4424b24473a8d571d2160ee7576",
      "9d5649b6391e44f5ad266c65fe71ec8e",
      "2dfa9272bd3a454582ebcd023d814301",
      "68fb67ba49274e2381586dfa12d4a00a",
      "de997021a80b4943b20c5518910ea387",
      "77a3b32f508c46f4a5bae2a29bbfc4f2",
      "5cdd60a9989c4e2fba367aa0fc23db04"
     ]
    },
    "colab_type": "code",
    "id": "q58IyfpGLyf4",
    "outputId": "73cb8853-c645-4bf7-d8e5-392613148c4a"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='../data', train=True, download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='../data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n4iXn51ILygD"
   },
   "source": [
    "This is a utility function to visualize torch Tensors as images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3EkoFimALygG"
   },
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    '''\n",
    "    Visualizes IMG.\n",
    "    IMG should be a 2D torch Tensor.\n",
    "    '''\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.detach().numpy()\n",
    "    plt.imshow(npimg, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Iu56FwY-LBc9"
   },
   "source": [
    "## Primal Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zAc2QEcALygQ"
   },
   "source": [
    "Here, we define the neural classifier we will be using. Note that the network comprises three layers. The first layer has dimension $28^2$ since this is the size of the input image. (The original inputs are square images, but we flatten them into a $28^2\\times 1$ vector in order to feed them into the network.) The output layer has dimension $10$, since there are ten possible output classes (the digits 0-9). The hidden layer has dimension $256$. (There isn't as much science behind choosing the dimensionality of input layers; we choose $256$ because it is a round number, and is hopefully enough to the neccesary encode information about the input image.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "6-joaa2DLygU",
    "outputId": "512b7136-2b3a-4487-837d-f8b3f554f582"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    \n",
    "    self.fc1 = nn.Linear(in_features=28*28, out_features = 256)\n",
    "    self.fc2 = nn.Linear(in_features=256, out_features = 10)\n",
    "    self.layers = [self.fc1, self.fc2]\n",
    "\n",
    "  # define forward function\n",
    "  def forward(self, t):\n",
    "    '''\n",
    "    On input T, performs a affine transformation, then\n",
    "    a ReLU, then another affine transformation.\n",
    "    '''\n",
    "    self.z = []\n",
    "    t = t.reshape(-1, 28*28)\n",
    "    t = self.fc1(t)\n",
    "    self.z.append(t)\n",
    "    t = F.relu(t)\n",
    "    t = self.fc2(t)\n",
    "    self.z.append(t)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YTue7LMGLygd"
   },
   "source": [
    "Here is the training code, which uses Adam, a variant of gradient descent. The actual optimization machinery is all abstracted away behind the torch library; all the work is being done by the `optimizer.step()` call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4zdMiOXDLygf"
   },
   "outputs": [],
   "source": [
    "def train(net, criterion, trainloader, lr=0.001):\n",
    "    '''\n",
    "    Uses the Adam optimization algorithm to train \n",
    "    the classifier NET on training data from TRAINLOADER,\n",
    "    on loss function CRITERION, with learning rate LR.\n",
    "    \n",
    "    Note that we half the learning rate each epoch.\n",
    "    '''\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(3):\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr * 0.5 ** (epoch)\n",
    "\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            if i % 500 == 0:\n",
    "                print('Epoch', epoch, 'Iter:', i, 'Loss', loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zmx06HSLLyhh"
   },
   "source": [
    "We can now train the net on the training data, using cross entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "colab_type": "code",
    "id": "W8pmvL6tLyhj",
    "outputId": "4d4e82cf-a525-485b-914c-d1afae757338"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4])\n",
      "Epoch 0 Iter: 0 Loss 2.2431833744049072\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "Epoch 0 Iter: 500 Loss 0.2919612228870392\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "Epoch 0 Iter: 1000 Loss 0.060013920068740845\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/patrickbales/Desktop/GitHub/AdversarialML/adversarial.ipynb Cell 20\u001b[0m in \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/patrickbales/Desktop/GitHub/AdversarialML/adversarial.ipynb#X25sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m net\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/patrickbales/Desktop/GitHub/AdversarialML/adversarial.ipynb#X25sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/patrickbales/Desktop/GitHub/AdversarialML/adversarial.ipynb#X25sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m train(net, criterion, trainloader, \u001b[39m0.001\u001b[39;49m)\n",
      "\u001b[1;32m/Users/patrickbales/Desktop/GitHub/AdversarialML/adversarial.ipynb Cell 20\u001b[0m in \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/patrickbales/Desktop/GitHub/AdversarialML/adversarial.ipynb#X25sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/patrickbales/Desktop/GitHub/AdversarialML/adversarial.ipynb#X25sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/patrickbales/Desktop/GitHub/AdversarialML/adversarial.ipynb#X25sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/patrickbales/Desktop/GitHub/AdversarialML/adversarial.ipynb#X25sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m%\u001b[39m \u001b[39m500\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/patrickbales/Desktop/GitHub/AdversarialML/adversarial.ipynb#X25sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mEpoch\u001b[39m\u001b[39m'\u001b[39m, epoch, \u001b[39m'\u001b[39m\u001b[39mIter:\u001b[39m\u001b[39m'\u001b[39m, i, \u001b[39m'\u001b[39m\u001b[39mLoss\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m.\u001b[39mitem())\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    281\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/optim/optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 33\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     34\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/optim/adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    130\u001b[0m     beta1, beta2 \u001b[39m=\u001b[39m group[\u001b[39m'\u001b[39m\u001b[39mbetas\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    132\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_group(\n\u001b[1;32m    133\u001b[0m         group,\n\u001b[1;32m    134\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    139\u001b[0m         state_steps)\n\u001b[0;32m--> 141\u001b[0m     adam(\n\u001b[1;32m    142\u001b[0m         params_with_grad,\n\u001b[1;32m    143\u001b[0m         grads,\n\u001b[1;32m    144\u001b[0m         exp_avgs,\n\u001b[1;32m    145\u001b[0m         exp_avg_sqs,\n\u001b[1;32m    146\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    147\u001b[0m         state_steps,\n\u001b[1;32m    148\u001b[0m         amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    149\u001b[0m         beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    150\u001b[0m         beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    151\u001b[0m         lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    152\u001b[0m         weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    153\u001b[0m         eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    154\u001b[0m         maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    155\u001b[0m         foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    156\u001b[0m         capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    157\u001b[0m         differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    158\u001b[0m         fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    159\u001b[0m         grad_scale\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mgrad_scale\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    160\u001b[0m         found_inf\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mfound_inf\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/optim/adam.py:281\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 281\u001b[0m func(params,\n\u001b[1;32m    282\u001b[0m      grads,\n\u001b[1;32m    283\u001b[0m      exp_avgs,\n\u001b[1;32m    284\u001b[0m      exp_avg_sqs,\n\u001b[1;32m    285\u001b[0m      max_exp_avg_sqs,\n\u001b[1;32m    286\u001b[0m      state_steps,\n\u001b[1;32m    287\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    288\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    289\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    290\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    291\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    292\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    293\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    294\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[1;32m    295\u001b[0m      differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[1;32m    296\u001b[0m      grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    297\u001b[0m      found_inf\u001b[39m=\u001b[39;49mfound_inf)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/optim/adam.py:345\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[39m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[1;32m    344\u001b[0m exp_avg\u001b[39m.\u001b[39mmul_(beta1)\u001b[39m.\u001b[39madd_(grad, alpha\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m beta1)\n\u001b[0;32m--> 345\u001b[0m exp_avg_sq\u001b[39m.\u001b[39;49mmul_(beta2)\u001b[39m.\u001b[39;49maddcmul_(grad, grad\u001b[39m.\u001b[39;49mconj(), value\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m \u001b[39m-\u001b[39;49m beta2)\n\u001b[1;32m    347\u001b[0m \u001b[39mif\u001b[39;00m capturable \u001b[39mor\u001b[39;00m differentiable:\n\u001b[1;32m    348\u001b[0m     step \u001b[39m=\u001b[39m step_t\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "net.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train(net, criterion, trainloader, 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "12zEbgnwLBdg"
   },
   "source": [
    "Let's load a sample image from the test dataset, and see what the classifier makes of it. Make sure to visualize the image using `imshow(x[0,0])`. Also, note that the line `test_iter.next()` pulls a new input image from the test set each time you run it; try running the next code block a few times to get a sense of what the MNIST dataset looks like, and how the classifier performs on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NFBwByD1LBdi"
   },
   "outputs": [],
   "source": [
    "test_iter = iter(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 322
    },
    "colab_type": "code",
    "id": "sB_m2TzpONdu",
    "outputId": "f09820e2-65df-4c6e-80fe-32432bd510b4"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier output: tensor([[ -5.5354,  -6.4766,  -0.6970,   0.8242, -18.0880,  -4.7428, -29.5170,\n",
      "           8.2390,  -7.0422,  -2.5172]])\n",
      "Classifier prediction: 7\n"
     ]
    }
   ],
   "source": [
    "x, labels = next(test_iter)\n",
    "x = x[0].unsqueeze(0)\n",
    "labels = labels[0].unsqueeze(0)\n",
    "imshow(x[0,0])\n",
    "\n",
    "x = x.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "out = net(x).data\n",
    "print('Classifier output:', out)\n",
    "print('Classifier prediction:', torch.argmax(out).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b6nekayzLygn"
   },
   "source": [
    "We can also measure the classifier's accuracy on the full test dataset. This function takes in a classifier we have trained and the loader for the test set, and outputs the classifier's accuracy. The accuracy is simply\n",
    "$$ \\dfrac{\\text{# correct}}{\\text{# total}}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lk4pq6hiLygr"
   },
   "outputs": [],
   "source": [
    "def accuracy(net, testloader):\n",
    "    '''\n",
    "    Returns the accuracy of classifier NET\n",
    "    on test data from TESTLOADER.\n",
    "    '''\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "kXpxjHkqLBd8",
    "outputId": "96b7766c-7368-4df9-dc0e-bc1c55b03d67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier accuracy on original test dataset: 0.967\n"
     ]
    }
   ],
   "source": [
    "print('Classifier accuracy on original test dataset:', accuracy(net, testloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rrvBEzmZLBeD"
   },
   "source": [
    "## Fast Gradient Sign Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p5ZlWjqILygz"
   },
   "source": [
    "Here, we implement the Fast Gradient Sign Method, which takes in a batch of input images, their labels, a trained classifier, and the epsilon radius within which the perturbation should lie. This function should output the input image perturbed in the direction of the sign of the gradient with respect to the classifier's loss.\n",
    "\n",
    "(Note that the output is not guaranteed to lie in the valid range for images, since here pixel values must be in $[-1,1]$. You should use `torch.clamp` to fix the FGSM output to lie in the correct range.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CaSK1tjSLyg2"
   },
   "outputs": [],
   "source": [
    "def FGSM(x, labels, net, eps):\n",
    "    '''\n",
    "    Given an input image X and its corresponding labels\n",
    "    LABELS, as well as a classifier NET, returns X\n",
    "    perturbed by EPS using the fast gradient sign method.\n",
    "    '''\n",
    "    net.zero_grad()    # Zero out any gradients from before\n",
    "    x.requires_grad=True    # Keep track of gradients\n",
    "    out = net(x)    # Output of classifier\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    loss = criterion(out, labels)   # Classifier's loss\n",
    "    loss.backward()\n",
    "    grads = x.grad.data    # Gradient of loss w/r/t input\n",
    "    return x + eps*torch.sign(grads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AB8K0vMsLBeU"
   },
   "source": [
    "Let's see how well the classifier does when the input is adversarially perturbed using FGSM. Try this for $\\varepsilon\\in\\{0.05, 0.1,0.2,0.3, 0.4\\}$, and again remember to visualize the inputs with `imshow`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 0.05 # TODO: Try eps = 0.05, 0.1, 0.2, 0.3, 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 322
    },
    "colab_type": "code",
    "id": "dbS2KvG6Lyh6",
    "outputId": "da1fe90b-4789-416b-f26c-2e950e9c33ad"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAbu0lEQVR4nO3dcWyU9R3H8U9BeqK219XSXm+UWkBlE+gyBrVTEUdDqYkRJZmof8BCJLpihtXpalTULaljixo3hv8sMBNRRyIwyUYC1ZbpCo4KQYJraO0GDFqU2Lu2SGH0tz8aT08K+Bx397073q/kSXr3PN8+X54+7Yen9/R7Wc45JwAAkmyEdQMAgIsTAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATl1g38HWDg4M6fPiwcnJylJWVZd0OAMAj55x6e3sVDAY1YsTZr3NSLoAOHz6skpIS6zYAABfo4MGDGjt27FnXp9yv4HJycqxbAADEwfl+nicsgFauXKmrrrpKl156qSoqKvT+++9/ozp+7QYAmeF8P88TEkBvvPGG6urqtHz5cn3wwQcqLy9XdXW1jh49mojdAQDSkUuAGTNmuNra2sjj06dPu2Aw6BoaGs5bGwqFnCQWFhYWljRfQqHQOX/ex/0K6OTJk2ptbVVVVVXkuREjRqiqqkotLS1nbD8wMKBwOBy1AAAyX9wD6NNPP9Xp06dVVFQU9XxRUZG6urrO2L6hoUF+vz+ycAccAFwczO+Cq6+vVygUiiwHDx60bgkAkARx/zuggoICjRw5Ut3d3VHPd3d3KxAInLG9z+eTz+eLdxsAgBQX9yug7OxsTZs2TY2NjZHnBgcH1djYqMrKynjvDgCQphIyCaGurk4LFy7UD37wA82YMUMvvvii+vv79ZOf/CQRuwMApKGEBNBdd92lTz75RE899ZS6urr0ve99T5s3bz7jxgQAwMUryznnrJv4qnA4LL/fb90GAOAChUIh5ebmnnW9+V1wAICLEwEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMJmYYNIDVcccUVSdtXX19f0vaFzMAVEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABNOwEbNkTlpG6kvW+cDU7czBFRAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATDCMFkFaSOQSXwaeJxRUQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwwjRcxiGdSYzEGSAFIbV0AAABMEEADARNwD6Omnn1ZWVlbUMmnSpHjvBgCQ5hLyGtB1112nrVu3frmTS3ipCQAQLSHJcMkllygQCCTiUwMAMkRCXgPav3+/gsGgxo8fr3vvvVcHDhw467YDAwMKh8NRCwAg88U9gCoqKrRmzRpt3rxZq1atUmdnp2666Sb19vYOu31DQ4P8fn9kKSkpiXdLAIAUlOWcc4ncQU9Pj0pLS/X8889r8eLFZ6wfGBjQwMBA5HE4HCaEMhh/B4R0EsvfuuFLoVBIubm5Z12f8LsD8vLydM0116i9vX3Y9T6fTz6fL9FtAABSTML/Dqivr08dHR0qLi5O9K4AAGkk7gH0yCOPqLm5Wf/+97/1j3/8Q3fccYdGjhypu+++O967AgCksbj/Cu7QoUO6++67dezYMY0ZM0Y33nijtm/frjFjxsR7VwCANJbwmxC8CofD8vv91m0gQbgJARa4mcDG+W5CYBYcAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwl/Qzok17x58zzXLFq0KKZ9ne1t1s/l2LFjnmtef/11zzVHjx71XCNJH3/8seeaTBywyvBOJANXQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAE1nOOWfdxFeFw2H5/X7rNtLWhx9+6LmmtLQ0AZ3YinWa80cffeS5hmnYyfXf//7Xc83zzz8f0752794dUx2GhEIh5ebmnnU9V0AAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMXGLdAOKrvr7ec82UKVNi2tc///lPzzWTJk3yXFNeXu65ZubMmZ5rJGn69Omea2IZjhnLcUimnp4ezzWffPKJ55pAIOC5Jpav0cGDBz3XSLENI0314bSpNGiWKyAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmGEaaYZqampJSE6utW7cmZT95eXkx1cUy+PSDDz7wXHPzzTd7rkmmTz/91HNNe3u755rW1lbPNePGjfNcE8u/R0r9waLpjisgAIAJAggAYMJzAG3btk233XabgsGgsrKytGHDhqj1zjk99dRTKi4u1ujRo1VVVaX9+/fHq18AQIbwHED9/f0qLy/XypUrh12/YsUKvfTSS3r55Ze1Y8cOXX755aqurtaJEycuuFkAQObwfBNCTU2Nampqhl3nnNOLL76oJ554Qrfffrsk6ZVXXlFRUZE2bNigBQsWXFi3AICMEdfXgDo7O9XV1aWqqqrIc36/XxUVFWppaRm2ZmBgQOFwOGoBAGS+uAZQV1eXJKmoqCjq+aKiosi6r2toaJDf748sJSUl8WwJAJCizO+Cq6+vVygUiiwHDx60bgkAkARxDaBAICBJ6u7ujnq+u7s7su7rfD6fcnNzoxYAQOaLawCVlZUpEAiosbEx8lw4HNaOHTtUWVkZz10BANKc57vg+vr6okZudHZ2avfu3crPz9e4ceO0bNky/epXv9LVV1+tsrIyPfnkkwoGg5o3b148+wYApDnPAbRz507dcsstkcd1dXWSpIULF2rNmjV69NFH1d/fryVLlqinp0c33nijNm/erEsvvTR+XQMA0l6Wc85ZN/FV4XBYfr/fuo2UkOqDEPv6+qxbSAmp/nWKRSxf2y/+9s+LV155xXPNvn37PNfceuutnmsk6dSpUzHVJUM6fP+FQqFzvq5vfhccAODiRAABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAw4fntGACkj1gnJo8ZM8ZzzQsvvOC5JpZ3QP7973/vueazzz7zXBOrTJyOnihcAQEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADDBMFLEPLAyEzFIcsiSJUs81xQUFHiuOXTokOeaXbt2ea7JRLGeq6n0/c4VEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMMI01hsQwNTPVhmqneX6a5/vrrY6p7+OGH49zJ8BYsWOC5Zt++fQnoJH6S9X2bSkNFY8UVEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMMI01hmTigMBMHrCZLLMeuuro6pn1dcon3Hw1NTU2ea3bs2OG5JtWl+vmaSj9XuAICAJgggAAAJjwH0LZt23TbbbcpGAwqKytLGzZsiFq/aNEiZWVlRS1z586NV78AgAzhOYD6+/tVXl6ulStXnnWbuXPn6siRI5Hltddeu6AmAQCZx/MrjTU1NaqpqTnnNj6fT4FAIOamAACZLyGvATU1NamwsFDXXnutHnjgAR07duys2w4MDCgcDkctAIDMF/cAmjt3rl555RU1Njbq17/+tZqbm1VTU6PTp08Pu31DQ4P8fn9kKSkpiXdLAIAUFPe/A1qwYEHk4ylTpmjq1KmaMGGCmpqaNHv27DO2r6+vV11dXeRxOBwmhADgIpDw27DHjx+vgoICtbe3D7ve5/MpNzc3agEAZL6EB9ChQ4d07NgxFRcXJ3pXAIA04vlXcH19fVFXM52dndq9e7fy8/OVn5+vZ555RvPnz1cgEFBHR4ceffRRTZw4MeaRIACAzOQ5gHbu3Klbbrkl8viL128WLlyoVatWac+ePfrTn/6knp4eBYNBzZkzR7/85S/l8/ni1zUAIO1lOeecdRNfFQ6H5ff7rdtACkn14Y7J8r///c9zzZYtW2La13e/+13PNbfeeqvnmmQNI+Uc+lIyBxaHQqFzvq7PLDgAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgIm4vyX3xSBZk3WTObUWyRXL1/YXv/iF55ry8nLPNZK0detWzzWxTLZmSnXsMuHnA1dAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATDCMNIVl4tDTTBw+Gcvxq66u9lzz2GOPea7p7e31XCNJzz33nOeaTPzaIrG4AgIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCYaRgiOQFys/P91zz29/+1nPNyJEjPde89957nmskad++fTHVAV5wBQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEw0hj0NfX57mGgZ/p4fjx455r/vrXv3quKS0t9VzT2dnpuebZZ5/1XAMkC1dAAAATBBAAwISnAGpoaND06dOVk5OjwsJCzZs3T21tbVHbnDhxQrW1tbryyit1xRVXaP78+eru7o5r0wCA9OcpgJqbm1VbW6vt27dry5YtOnXqlObMmaP+/v7INg899JDeeustrVu3Ts3NzTp8+LDuvPPOuDcOAEhvnm5C2Lx5c9TjNWvWqLCwUK2trZo5c6ZCoZD++Mc/au3atfrRj34kSVq9erW+853vaPv27br++uvj1zkAIK1d0GtAoVBI0pdvSdza2qpTp06pqqoqss2kSZM0btw4tbS0DPs5BgYGFA6HoxYAQOaLOYAGBwe1bNky3XDDDZo8ebIkqaurS9nZ2crLy4vatqioSF1dXcN+noaGBvn9/shSUlISa0sAgDQScwDV1tZq7969ev311y+ogfr6eoVCochy8ODBC/p8AID0ENMfoi5dulSbNm3Stm3bNHbs2MjzgUBAJ0+eVE9PT9RVUHd3twKBwLCfy+fzyefzxdIGACCNeboCcs5p6dKlWr9+vd5++22VlZVFrZ82bZpGjRqlxsbGyHNtbW06cOCAKisr49MxACAjeLoCqq2t1dq1a7Vx40bl5OREXtfx+/0aPXq0/H6/Fi9erLq6OuXn5ys3N1cPPvigKisruQMOABDFUwCtWrVKkjRr1qyo51evXq1FixZJkl544QWNGDFC8+fP18DAgKqrq/WHP/whLs0CADJHlnPOWTfxVeFwWH6/37qNc2KwaOaaOHGi55pdu3YloJMz/fjHP/Zc87e//S0BnSDeYhlwnA5CoZByc3PPup5ZcAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEzG9IyqQ6r76Tr1e/OUvf4lzJ8N7/PHHPdesW7fOcw2T25MvUydbJwJXQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwwjDQGsQwbZChkci1evDimupKSkjh3Mry///3vnms4h9JDLF+ni3WAKVdAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATDCMNEkycdhgsoZj/vCHP/Rcc//99yegE1uZOAQ31f9Nmfh9m0q4AgIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCYaSIWbIGNVZWVnquSebAyo8//thzzdGjRxPQyZkYpjmE45CauAICAJgggAAAJjwFUENDg6ZPn66cnBwVFhZq3rx5amtri9pm1qxZysrKiloy8b1ZAAAXxlMANTc3q7a2Vtu3b9eWLVt06tQpzZkzR/39/VHb3XfffTpy5EhkWbFiRVybBgCkP083IWzevDnq8Zo1a1RYWKjW1lbNnDkz8vxll12mQCAQnw4BABnpgl4DCoVCkqT8/Pyo51999VUVFBRo8uTJqq+v1/Hjx8/6OQYGBhQOh6MWAEDmi/k27MHBQS1btkw33HCDJk+eHHn+nnvuUWlpqYLBoPbs2aPHHntMbW1tevPNN4f9PA0NDXrmmWdibQMAkKZiDqDa2lrt3btX7777btTzS5YsiXw8ZcoUFRcXa/bs2ero6NCECRPO+Dz19fWqq6uLPA6HwyopKYm1LQBAmogpgJYuXapNmzZp27ZtGjt27Dm3raiokCS1t7cPG0A+n08+ny+WNgAAacxTADnn9OCDD2r9+vVqampSWVnZeWt2794tSSouLo6pQQBAZvIUQLW1tVq7dq02btyonJwcdXV1SZL8fr9Gjx6tjo4OrV27VrfeequuvPJK7dmzRw899JBmzpypqVOnJuQfAABIT54CaNWqVZKG/tj0q1avXq1FixYpOztbW7du1Ysvvqj+/n6VlJRo/vz5euKJJ+LWMAAgM3j+Fdy5lJSUqLm5+YIaAgBcHJiGjZSXzEnGH374oeeam2++2XPNZ5995rkGQ5hsnTkYRgoAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMBEljvfiOskC4fD8vv91m0AAC5QKBRSbm7uWddzBQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEykXQCk2mg4AEKPz/TxPuQDq7e21bgEAEAfn+3mectOwBwcHdfjwYeXk5CgrKytqXTgcVklJiQ4ePHjOCauZjuMwhOMwhOMwhOMwJBWOg3NOvb29CgaDGjHi7Nc5lySxp29kxIgRGjt27Dm3yc3NvahPsC9wHIZwHIZwHIZwHIZYH4dv8rY6KfcrOADAxYEAAgCYSKsA8vl8Wr58uXw+n3UrpjgOQzgOQzgOQzgOQ9LpOKTcTQgAgItDWl0BAQAyBwEEADBBAAEATBBAAAATaRNAK1eu1FVXXaVLL71UFRUVev/9961bSrqnn35aWVlZUcukSZOs20q4bdu26bbbblMwGFRWVpY2bNgQtd45p6eeekrFxcUaPXq0qqqqtH//fptmE+h8x2HRokVnnB9z5861aTZBGhoaNH36dOXk5KiwsFDz5s1TW1tb1DYnTpxQbW2trrzySl1xxRWaP3++uru7jTpOjG9yHGbNmnXG+XD//fcbdTy8tAigN954Q3V1dVq+fLk++OADlZeXq7q6WkePHrVuLemuu+46HTlyJLK8++671i0lXH9/v8rLy7Vy5cph169YsUIvvfSSXn75Ze3YsUOXX365qqurdeLEiSR3mljnOw6SNHfu3Kjz47XXXktih4nX3Nys2tpabd++XVu2bNGpU6c0Z84c9ff3R7Z56KGH9NZbb2ndunVqbm7W4cOHdeeddxp2HX/f5DhI0n333Rd1PqxYscKo47NwaWDGjBmutrY28vj06dMuGAy6hoYGw66Sb/ny5a68vNy6DVOS3Pr16yOPBwcHXSAQcL/5zW8iz/X09Difz+dee+01gw6T4+vHwTnnFi5c6G6//XaTfqwcPXrUSXLNzc3OuaGv/ahRo9y6desi23z00UdOkmtpabFqM+G+fhycc+7mm292P/vZz+ya+gZS/gro5MmTam1tVVVVVeS5ESNGqKqqSi0tLYad2di/f7+CwaDGjx+ve++9VwcOHLBuyVRnZ6e6urqizg+/36+KioqL8vxoampSYWGhrr32Wj3wwAM6duyYdUsJFQqFJEn5+fmSpNbWVp06dSrqfJg0aZLGjRuX0efD14/DF1599VUVFBRo8uTJqq+v1/Hjxy3aO6uUG0b6dZ9++qlOnz6toqKiqOeLior0r3/9y6grGxUVFVqzZo2uvfZaHTlyRM8884xuuukm7d27Vzk5Odbtmejq6pKkYc+PL9ZdLObOnas777xTZWVl6ujo0OOPP66amhq1tLRo5MiR1u3F3eDgoJYtW6YbbrhBkydPljR0PmRnZysvLy9q20w+H4Y7DpJ0zz33qLS0VMFgUHv27NFjjz2mtrY2vfnmm4bdRkv5AMKXampqIh9PnTpVFRUVKi0t1Z///GctXrzYsDOkggULFkQ+njJliqZOnaoJEyaoqalJs2fPNuwsMWpra7V3796L4nXQcznbcViyZEnk4ylTpqi4uFizZ89WR0eHJkyYkOw2h5Xyv4IrKCjQyJEjz7iLpbu7W4FAwKir1JCXl6drrrlG7e3t1q2Y+eIc4Pw40/jx41VQUJCR58fSpUu1adMmvfPOO1Fv3xIIBHTy5En19PREbZ+p58PZjsNwKioqJCmlzoeUD6Ds7GxNmzZNjY2NkecGBwfV2NioyspKw87s9fX1qaOjQ8XFxdatmCkrK1MgEIg6P8LhsHbs2HHRnx+HDh3SsWPHMur8cM5p6dKlWr9+vd5++22VlZVFrZ82bZpGjRoVdT60tbXpwIEDGXU+nO84DGf37t2SlFrng/VdEN/E66+/7nw+n1uzZo3bt2+fW7JkicvLy3NdXV3WrSXVww8/7JqamlxnZ6d77733XFVVlSsoKHBHjx61bi2hent73a5du9yuXbucJPf888+7Xbt2uf/85z/OOeeee+45l5eX5zZu3Oj27Nnjbr/9dldWVuY+//xz487j61zHobe31z3yyCOupaXFdXZ2uq1bt7rvf//77uqrr3YnTpywbj1uHnjgAef3+11TU5M7cuRIZDl+/Hhkm/vvv9+NGzfOvf32227nzp2usrLSVVZWGnYdf+c7Du3t7e7ZZ591O3fudJ2dnW7jxo1u/PjxbubMmcadR0uLAHLOud/97ndu3LhxLjs7282YMcNt377duqWku+uuu1xxcbHLzs523/72t91dd93l2tvbrdtKuHfeecdJOmNZuHChc27oVuwnn3zSFRUVOZ/P52bPnu3a2tpsm06Acx2H48ePuzlz5rgxY8a4UaNGudLSUnffffdl3H/Shvv3S3KrV6+ObPP555+7n/70p+5b3/qWu+yyy9wdd9zhjhw5Ytd0ApzvOBw4cMDNnDnT5efnO5/P5yZOnOh+/vOfu1AoZNv41/B2DAAAEyn/GhAAIDMRQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAw8X9XxwbMTEDQUAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier output: tensor([[ -4.4381,  -6.5098,   0.1110,   2.2160, -18.5287,  -3.5059, -27.7980,\n",
      "           6.7764,  -5.1946,  -2.6820]])\n",
      "Classifier prediction: 7\n"
     ]
    }
   ],
   "source": [
    "# We are using the same sample input x as before.\n",
    "x.requires_grad = True\n",
    "x_prime = FGSM(x, labels, net, eps)\n",
    "imshow(x_prime[0,0].cpu())\n",
    "out = net(x_prime)\n",
    "\n",
    "print('Classifier output:', out.data)\n",
    "print('Classifier prediction:', torch.argmax(out).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "64qakoWaLBec"
   },
   "source": [
    "We should evaluate the classifier's performance on FGSM-perturbed data by the same metric that we will later use in the primal adversarial problem. That is, for the classifier's output vector $\\vec{\\hat{z}}_3$, we want to compute\n",
    "$$\n",
    "\\vec{c}_j^\\top \\vec{\\hat{z}}_3\n",
    "$$\n",
    "where\n",
    "$$\\vec{c}_j={\\vec{y}_{\\text{true}}}-\\vec{e}_{j}$$\n",
    "for each $j\\in[10]$.\n",
    "\n",
    "Recall that \n",
    "$$\\vec{c}_j^\\top \\vec{\\hat{z}}_3=\\vec{\\hat{z}}_{3i_{\\text{true}}}-\\vec{\\hat{z}}_{3j},$$\n",
    "i.e. $\\vec{c}_j^\\top \\vec{\\hat{z}}_3$ is the difference between the classifier's confidence on the true class and the $j$th (incorrect) class. If $\\vec{c}_j^\\top \\vec{\\hat{z}}_3$ is positive for all incorrect $j$, then the classifier was not fooled by the adversarial perturbation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "qpFjSe3ULBee",
    "outputId": "6256f017-d100-4f24-b932-ea6c67b8710e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 11.214488983154297\n",
      "1 13.286153793334961\n",
      "2 6.66534948348999\n",
      "3 4.560339450836182\n",
      "4 25.30509376525879\n",
      "5 10.282257080078125\n",
      "6 34.57434844970703\n",
      "8 11.970928192138672\n",
      "9 9.458379745483398\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    c = torch.zeros(10, 1).to(device)\n",
    "    if i != labels:\n",
    "        c[i] = -1\n",
    "        c[labels] = 1\n",
    "        print(i, (out @ c).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q4JTyFqQLBeo"
   },
   "source": [
    "**Q: What do the $\\vec{c}_j^\\top \\vec{\\hat{z}}_3$ scores tell you about the robustness of the classifier to different values of epsilon? For a given input digit, which output categories have higher/lower scores? Why?**\n",
    "\n",
    "A: <font color=red> The larger the $\\vec{c}_j^\\top \\vec{\\hat{z}}_3$ scores, the higher the robustness of the classifier is to larger epsilon.  As epsilon gets larger, the smallest $\\vec{c}_j^\\top \\vec{\\hat{z}}_3$ scores will gradually get smaller until they are negative, indicating that the classifier was fooled by the adversarial pertubation. Since all of the above scores are positive for eps=0.05, we know that the classifier was robust enough to not be fooled/affected by the adversarial pertubation, whereas for eps=0.2, the classifier was fooled into believing the image was of a 2 (which makes sense since 2 always had the lowest $\\vec{c}_j^\\top \\vec{\\hat{z}}_3$ scores of the possible options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LaGNmioNLyg_"
   },
   "source": [
    "Now that FGSM is defined, we can also measure a classifier's accuracy on a dataset where each input has been adversarially perturbed. That is, for each point in the original test dataset, we first perturb it using FGSM before feeding it to the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ik9xXp3hLyhB"
   },
   "outputs": [],
   "source": [
    "def accuracy_on_FGSM(net, testloader, eps):\n",
    "    '''\n",
    "    Returns the accuracy of classifier NET on test\n",
    "    data from TESTLOADER that has been perturbed by\n",
    "    EPS using FSGM.\n",
    "    '''\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in testloader:\n",
    "        x, labels = data[0].to(device), data[1].to(device)\n",
    "        x_prime = FGSM(x, labels, net, eps)\n",
    "        outputs = net(x_prime)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "PDD_z76ALBew",
    "outputId": "01ccf72d-1bab-4ce7-ab00-d202779e0937"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier accuracy on test dataset perturbed with FGSM: 0.8792\n"
     ]
    }
   ],
   "source": [
    "print('Classifier accuracy on test dataset perturbed with FGSM:', accuracy_on_FGSM(net, testloader, eps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dj-7r-oqLBe1"
   },
   "source": [
    "**Q: How does the classifier accuracy on data perturbed by FGSM compare to that on the original test dataset? How does this vary with epsilon?**\n",
    "\n",
    "A: The FGSM perturbed data leads to much lower accuracy than on the original dataset. As epsilon increases, the classifier becomes less accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jDwEDxf9LBe7"
   },
   "source": [
    "## Dual Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AkVG-qEuLyhK"
   },
   "source": [
    "Here, we will implement the dual network. First, we write the function to compute upper and lower bounds for the dual network. This function should take an input image, the trained classifier, and an epsilon value, and return the tuple\n",
    "$$(\\vec{l},\\vec{u},S,S^-,S^+)$$\n",
    "where $\\vec{u}$ and $\\vec{l}$ are the upper and lower bounds, respectively, for the input to the ReLU layer, and $S^-,S^+,S$ are sets defined by\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&S:=\\{j\\in [n_2]\\mid l_{j}\\leq 0\\leq u_{j}\\}\\\\\n",
    "&S^{-}:=\\{j\\in [n_2]\\mid l_{j}\\leq u_{j}\\leq 0\\}\\\\\n",
    "&S^{+}:=\\{j\\in [n_2]\\mid 0\\leq l_{j}\\leq u_{j}\\}.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "See Section 6 of the PDF for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_0QHBHTHLyhO"
   },
   "outputs": [],
   "source": [
    "def dual_bounds(x, net, eps):\n",
    "    '''\n",
    "    Given a classifier NET, an input image X,\n",
    "    and the epsilon parameter EPS, returns the lower\n",
    "    and upper bounds L and U respectively, as well as\n",
    "    the corresponding sets S, S_MIN, S_PLUS.\n",
    "    '''\n",
    "    x = x[0].reshape(-1, 1)    # Reshape input to more convenient dimensions\n",
    "    W = [layer.weight for layer in net.layers]    # Array of network weights (W matrices)\n",
    "    b = [layer.bias.reshape(-1, 1) for layer in net.layers]    # Array of network biases (b vectors)\n",
    "    n = W[1].shape[1]    # Dimensionality of hidden layer\n",
    "\n",
    "    u = torch.Tensor([W[0][i] @ x + b[0][i] + eps * torch.norm(W[0][i], 1) for i in range(0, n)])\n",
    "    l = torch.Tensor([W[0][i] @ x + b[0][i] - eps * torch.norm(W[0][i], 1) for i in range(0, n)])\n",
    "\n",
    "    S = [i for i in range(0, n) if l[i] <= 0 and u[i] >= 0]\n",
    "    S_plus = [i for i in range(0, n) if l[i] <= u[i] and l[i] >= 0]\n",
    "    S_min = [i for i in range(0, n) if u[i] <= 0 and u[i] >= l[i]]\n",
    "    \n",
    "    return l, u, S, S_min, S_plus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VaMhcqTvLyhX"
   },
   "source": [
    "Given the tuple $(l,u,S,S^-,S^+)$, we are ready to calculate the dual objective itself. This function should take in an input image, the classifier, a vector $c$, and the $(l,u,S,S^-,S^+)$ from the previous function in order to output \n",
    "$$\n",
    "d^*(\\vec{x},\\vec{c})= \n",
    "-\\vec{\\hat{\\nu}}_1^\\top \\vec{x}-\\varepsilon\\|\\vec{\\hat{\\nu}}_1\\|_1-\\sum_{i=1}^{2}\\vec{\\nu}_{i+1}^\\top \\vec{b}_i+\\sum_{j\\in S\\\n",
    "}l_{j}\\text{ReLU}(\\nu_{2j})\n",
    "$$\n",
    "\n",
    "Where the $\\vec{\\nu}$ vectors are computed as\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&\\vec{\\nu}_3=-\\vec{c}\\\\\n",
    "&\\vec{\\hat{\\nu}}_2=W_2^\\top \\vec{\\nu}_{3}\\\\\n",
    "&\\nu_{2j}=0 && \\forall j\\in S^-\\\\\n",
    "&\\nu_{2j}=\\hat{\\nu}_{2j} && \\forall j\\in S^+\\\\\n",
    "&\\nu_{2j}=\\dfrac{u_{j}}{u_{j}-l_{j}}\\hat{\\nu}_{2j} && \\forall j\\in S\\\\\n",
    "&\\vec{\\hat{\\nu}}_1=W_1^\\top \\vec{\\nu_{2}}\n",
    "&\\end{aligned}.\n",
    "$$\n",
    "\n",
    "Again, see Section 6 of the PDF for more details.\n",
    "\n",
    "One efficient way to compute $\\vec{\\nu}_2$ is to rewrite it as\n",
    "$$\\vec{\\nu}_2= D\\vec{\\hat{\\nu}}_2,$$\n",
    "where $D$ is a diagonal matrix defined  by\n",
    "$$\n",
    "D_{jj}=\\begin{cases}\n",
    "0 & j\\in S^-\\\\\n",
    "\\hat{\\nu}_{2j} & j\\in S^+\\\\\n",
    "\\dfrac{u_{j}}{u_{j}-l_{j}}\\hat{\\nu}_{2j} & j\\in S.\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "chl5lue0Lyha"
   },
   "outputs": [],
   "source": [
    "# Constructs the diagonal D matrix from the S sets, n (the dimensionality\n",
    "# of the hidden layer), u, and l.\n",
    "def StoD(S_min, S_plus, S, n, u, l):\n",
    "    '''\n",
    "    Given upper and lower bounds U and L, as well\n",
    "    as the corresponding sets S_MIN, S_PLUS, and S,\n",
    "    as well as the dimension of the hidden layer N,\n",
    "    returns the corresponding diagonal matrix D.\n",
    "    '''\n",
    "    d = []\n",
    "    for j in range(n):\n",
    "        if j in S:\n",
    "            d.append((u[j] / (u[j] - l[j])).item())\n",
    "        elif j in S_plus:\n",
    "            d.append(1)\n",
    "        elif j in S_min:\n",
    "            d.append(0)\n",
    "        else:\n",
    "            assert False, 'StoD error.'\n",
    "    return torch.diag(torch.Tensor(d)).to(device)\n",
    "\n",
    "def dual_forward(x, net, c, eps, l, u, S, S_min, S_plus):\n",
    "    '''\n",
    "    Calculates the dual objective for classifier NET with input X\n",
    "    and dual input C and epsilon parameter S. Depends on lower\n",
    "    and upper bounds L and U, as well as the corresponding sets\n",
    "    S, S_MIN, S_PLUS.\n",
    "    '''\n",
    "    x = x[0].reshape(-1, 1)    # Reshape input to more convenient dimensions\n",
    "    W = [layer.weight for layer in net.layers]    # Array of network weights (W matrices)\n",
    "    b = [layer.bias.reshape(-1, 1) for layer in net.layers]    # Array of network biases (b vectors)\n",
    "    n = W[1].shape[1]    # Dimensionality of hidden layer\n",
    "    D = StoD(S_min, S_plus, S, n, u, l)\n",
    "\n",
    "    nu3 = -c\n",
    "    nuh2 = W[1].T @ nu3\n",
    "    nu2 = D @ nuh2\n",
    "    nuh1 = W[0].T @ nu2\n",
    "    relu_sum = 0\n",
    "    for i in range(len(nu2)):\n",
    "        if i in S:\n",
    "            relu_sum += l[i] * torch.relu(nu2[i])  \n",
    "    dual = -1 * (nuh1.T @ x) - eps * (torch.norm(nuh1, 1)) - (nu2.T @ b[0]) - (nu3.T @ b[1]) + relu_sum\n",
    "\n",
    "    return dual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HagySRiNLyhu"
   },
   "source": [
    "Now, we can use the dual network to check the robustness of the network we just trained on sample input images. We can do this for \n",
    "$$\\vec{c}_j={\\vec{y}_{\\text{true}}}-\\vec{e}_{j}$$\n",
    "for each $j\\in[10]$.\n",
    "\n",
    "The output is a vector where the $j$th element is the difference between the model's confidence in the true class and the $j$th class; if $d^*(\\vec{x},\\vec{c}_j)$ is nonnegative for every $j\\in[10]$, then we know the model is robust to perturbations of size $\\varepsilon$. See Section 8 of the PDF for more details.\n",
    "\n",
    "Try running the following block of code for different values of $\\varepsilon\\in\\{0.05, 0.1, 0.2, 0.3, 0.4\\}$, and compare the robustness guarantees here with the classifier's performance on the FGSM data from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 0.05 # TODO: Try eps = 0.05, 0.1, 0.2, 0.3, 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "WY6TfL2GLyhw",
    "outputId": "41886f00-c9f7-4f6d-b227-1bb5fe647a19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7557121515274048\n",
      "1 8.49767017364502\n",
      "2 -0.48657000064849854\n",
      "3 -0.0526735782623291\n",
      "4 15.635282516479492\n",
      "5 4.521230697631836\n",
      "6 22.276962280273438\n",
      "8 4.820800304412842\n",
      "9 2.162574052810669\n"
     ]
    }
   ],
   "source": [
    "# We are still using the same sample input x as before.\n",
    "l, u, S, S_min, S_plus = dual_bounds(x, net, eps)\n",
    "\n",
    "# print(l, u, S, S_min, S_plus)\n",
    "# Here, we loop through each column c_j defined above, and output the \n",
    "# objective value for the dual function with input c.\n",
    "for i in range(10):\n",
    "    c = torch.zeros(10, 1).to(device)\n",
    "    if i != labels:\n",
    "        c[i] = -1\n",
    "        c[labels] = 1\n",
    "        print(i, dual_forward(x, net, c, 0.1, l, u, S, S_min, S_plus).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v--Zs9ELLyiB"
   },
   "source": [
    "**Q: What do the dual network outputs tell you about the robustness of the classifier? How does this compare to the classifier's performance (in particular, the $\\vec{c}_j^\\top \\vec{\\hat{z}}_3$ scores) on FGSM outputs? How does your answer change with epsilon?**\n",
    "\n",
    "A: <font color=red> The dual network outputs have much higher scores, which indicates a much more robust classifier. This classifier therefore does much better on FGSM outputs. However, at epsilon=0.29, we do begin to see failure. Lower epsilon leads to even higher scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dr3xSI7EMv4l"
   },
   "source": [
    "**Q: Suppose you have a deep neural classifier that you want to defend against adversarial attacks. That is, you want to detect and discard any input images that were possibly adversarially perturbed. How might you do this with the robustness certificate you have implemented?**\n",
    "\n",
    "A: <font color=red> Minimizing over the worst case loss from the dual network has allowed us to create a robustness certificate that ensures a provably robust network. Should an image exceed our estimated worst case loss calculated by the dual or approach it, it is likely that this input was adversarially perturbed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s--Ae8VpLyiN"
   },
   "source": [
    "## Robust training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LohSkAUMLBfa"
   },
   "source": [
    "The following function should implement the robust loss from section A of the PDF. This loss is an upper bound on the worst-case loss within an $\\epsilon$ ball of the original training input. Thus, training using this new loss should result in a classifier that is more robust than one trained on the original cross-entropy loss.\n",
    "\n",
    "There are no mandatory questions here, but feel free to experiment with this robust training, and compare the performance here (measured by the dual objective certificate, as well as original/FGSM accuracy) to that of the original. You can also try training a model using the original loss first, then fine-tuning with the robust loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uTv9zjuqLyiQ"
   },
   "outputs": [],
   "source": [
    "def robust_loss(x, label, net, eps, criterion):\n",
    "    '''\n",
    "    Given a batch of input images X, its corresponding lables LABEL,\n",
    "    the classifier NET, epsilon value EPS, and original loss\n",
    "    function CRITERION, returns the robust loss of NET w/r/t\n",
    "    the original loss function, on the input image.\n",
    "    '''\n",
    "    l, u, S, S_min, S_plus = dual_bounds(x, net, eps)\n",
    "    # We assume there are 10 classes.\n",
    "    e_y = torch.zeros(10, 1)\n",
    "    e_y[label] = 1\n",
    "    c = e_y @ torch.ones(1, 10) - torch.eye(10)\n",
    "    J = dual_forward(x, net, c, 0.1, l, u, S, S_min, S_plus).unsqueeze(0)\n",
    "    print(J.size())\n",
    "    try:\n",
    "        temp = criterion(-J, label.unsqueeze(0))\n",
    "    except:\n",
    "        temp = criterion(-J, label.unsqueeze(0).expand(1,10))\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nj_VkNaNLyiY"
   },
   "outputs": [],
   "source": [
    "def robust_train(net, criterion, trainloader, eps, lr=0.001):\n",
    "    '''\n",
    "    Trains the classifier NET using the robust version\n",
    "    of the original loss function CRITERION with paramater EPS,\n",
    "    using training data from TRAINLOADER and with learning rate LR.\n",
    "    \n",
    "    Note that we half the learning rate each epoch.\n",
    "    '''\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(1):\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr * 0.5 ** (epoch)\n",
    "\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            loss = 0\n",
    "            for k in range(inputs.shape[0]):\n",
    "                x = inputs[k].unsqueeze(0)\n",
    "                label = labels[k].unsqueeze(0)\n",
    "                loss += robust_loss(x, label, net, eps, criterion)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            if i % 500 == 0:\n",
    "                print('Epoch', epoch, 'Iter:', i, 'Loss', loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='../data', train=True, download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='../data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 10])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected target size [1, 10], got [1, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/patrickbales/Desktop/GitHub/AdversarialML/adversarial.ipynb Cell 55\u001b[0m in \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/patrickbales/Desktop/GitHub/AdversarialML/adversarial.ipynb#Y105sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m eps \u001b[39m=\u001b[39m \u001b[39m0.05\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/patrickbales/Desktop/GitHub/AdversarialML/adversarial.ipynb#Y105sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/patrickbales/Desktop/GitHub/AdversarialML/adversarial.ipynb#Y105sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m robust_train(net, criterion, trainloader, \u001b[39m0.001\u001b[39;49m)\n",
      "\u001b[1;32m/Users/patrickbales/Desktop/GitHub/AdversarialML/adversarial.ipynb Cell 55\u001b[0m in \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/patrickbales/Desktop/GitHub/AdversarialML/adversarial.ipynb#Y105sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     x \u001b[39m=\u001b[39m inputs[k]\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/patrickbales/Desktop/GitHub/AdversarialML/adversarial.ipynb#Y105sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     label \u001b[39m=\u001b[39m labels[k]\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/patrickbales/Desktop/GitHub/AdversarialML/adversarial.ipynb#Y105sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m robust_loss(x, label, net, eps, criterion)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/patrickbales/Desktop/GitHub/AdversarialML/adversarial.ipynb#Y105sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/patrickbales/Desktop/GitHub/AdversarialML/adversarial.ipynb#Y105sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "\u001b[1;32m/Users/patrickbales/Desktop/GitHub/AdversarialML/adversarial.ipynb Cell 55\u001b[0m in \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/patrickbales/Desktop/GitHub/AdversarialML/adversarial.ipynb#Y105sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m J \u001b[39m=\u001b[39m dual_forward(x, net, c, \u001b[39m0.1\u001b[39m, l, u, S, S_min, S_plus)\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/patrickbales/Desktop/GitHub/AdversarialML/adversarial.ipynb#Y105sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mprint\u001b[39m(J\u001b[39m.\u001b[39msize())\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/patrickbales/Desktop/GitHub/AdversarialML/adversarial.ipynb#Y105sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mreturn\u001b[39;00m criterion(\u001b[39m-\u001b[39;49mJ, label\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m0\u001b[39;49m))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/loss.py:1174\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m-> 1174\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mcross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m   1175\u001b[0m                            ignore_index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mignore_index, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction,\n\u001b[1;32m   1176\u001b[0m                            label_smoothing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel_smoothing)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/functional.py:3029\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3027\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3028\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3029\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mcross_entropy_loss(\u001b[39minput\u001b[39;49m, target, weight, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction), ignore_index, label_smoothing)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected target size [1, 10], got [1, 1]"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "net.to(device)\n",
    "\n",
    "eps = 0.05\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "robust_train(net, criterion, trainloader, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter = iter(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, labels = next(test_iter)\n",
    "x = x[0].unsqueeze(0)\n",
    "labels = labels[0].unsqueeze(0)\n",
    "imshow(x[0,0])\n",
    "\n",
    "x = x.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "out = net(x).data\n",
    "print('Classifier output:', out)\n",
    "print('Classifier prediction:', torch.argmax(out).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(net, testloader):\n",
    "    '''\n",
    "    Returns the accuracy of classifier NET\n",
    "    on test data from TESTLOADER.\n",
    "    '''\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Classifier accuracy on original test dataset:', accuracy(net, testloader))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "torch_impl_sol.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "080f0e9e20374c8b9d0772c207d40204": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0d2ab5e4e4634c2d84445dcb59e63093": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "0ffb65b8fcd64017a1575ef5c6fb6783": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e0fc65863e247bba684aa570176e47e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9b0d7cc1d4a84b32ad704d0f92aaf7c2",
       "IPY_MODEL_359ca0eaed76461b8920085a62f10151"
      ],
      "layout": "IPY_MODEL_0ffb65b8fcd64017a1575ef5c6fb6783"
     }
    },
    "2dfa9272bd3a454582ebcd023d814301": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5cdd60a9989c4e2fba367aa0fc23db04",
      "placeholder": "​",
      "style": "IPY_MODEL_77a3b32f508c46f4a5bae2a29bbfc4f2",
      "value": " 8192/? [00:06&lt;00:00, 1348.53it/s]"
     }
    },
    "359ca0eaed76461b8920085a62f10151": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_080f0e9e20374c8b9d0772c207d40204",
      "placeholder": "​",
      "style": "IPY_MODEL_7cb630c6d3784c0ba705b39311a36690",
      "value": " 0/28881 [00:00&lt;?, ?it/s]"
     }
    },
    "3ce16927200e4dfbba645b52ede3be15": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_51fab2724f5240f2a197da36bfb5d37f",
      "placeholder": "​",
      "style": "IPY_MODEL_7f3be4825b3942bfbd15404ae2826968",
      "value": " 9920512/? [00:20&lt;00:00, 1533441.80it/s]"
     }
    },
    "40781e910ad14961b70299654d08af57": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "410b4797b4eb474185b6e9e8768efe90": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "443bc19134b346e282b58b81de72ee9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d51c1aaaee7e40eb9a6946ee964f26db",
       "IPY_MODEL_75a9df895ea94bb787ead957f9b540c9"
      ],
      "layout": "IPY_MODEL_be2ab404919947b6bec6e47d8ef2293e"
     }
    },
    "48f34dff73514ae58be4a78b897605de": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "51fab2724f5240f2a197da36bfb5d37f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5cdd60a9989c4e2fba367aa0fc23db04": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "68fb67ba49274e2381586dfa12d4a00a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "73155d071971464cac0ed23138cde635": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "75a9df895ea94bb787ead957f9b540c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ad74039e867d489fbcc6c9d8ff34706c",
      "placeholder": "​",
      "style": "IPY_MODEL_73155d071971464cac0ed23138cde635",
      "value": " 1654784/? [00:06&lt;00:00, 244349.52it/s]"
     }
    },
    "77a3b32f508c46f4a5bae2a29bbfc4f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7cb630c6d3784c0ba705b39311a36690": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7f3be4825b3942bfbd15404ae2826968": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "86cdc4424b24473a8d571d2160ee7576": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a08a24593a2422985302484dc4594d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "8c6d1f7d352a4c089e4ae601a73c1068": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_410b4797b4eb474185b6e9e8768efe90",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8a08a24593a2422985302484dc4594d1",
      "value": 1
     }
    },
    "9601fc4be35543a784d4231a2de31edb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9b0d7cc1d4a84b32ad704d0f92aaf7c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "  0%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c75be203b59b4c599fd51b44b5359236",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0d2ab5e4e4634c2d84445dcb59e63093",
      "value": 0
     }
    },
    "9d5649b6391e44f5ad266c65fe71ec8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_de997021a80b4943b20c5518910ea387",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_68fb67ba49274e2381586dfa12d4a00a",
      "value": 1
     }
    },
    "ad74039e867d489fbcc6c9d8ff34706c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bde4879694234dc087cc6ef3a8f999e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9d5649b6391e44f5ad266c65fe71ec8e",
       "IPY_MODEL_2dfa9272bd3a454582ebcd023d814301"
      ],
      "layout": "IPY_MODEL_86cdc4424b24473a8d571d2160ee7576"
     }
    },
    "be2ab404919947b6bec6e47d8ef2293e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c33f5dd2c1f443f1b771f0c46054eebf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8c6d1f7d352a4c089e4ae601a73c1068",
       "IPY_MODEL_3ce16927200e4dfbba645b52ede3be15"
      ],
      "layout": "IPY_MODEL_9601fc4be35543a784d4231a2de31edb"
     }
    },
    "c75be203b59b4c599fd51b44b5359236": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d51c1aaaee7e40eb9a6946ee964f26db": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_48f34dff73514ae58be4a78b897605de",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_40781e910ad14961b70299654d08af57",
      "value": 1
     }
    },
    "de997021a80b4943b20c5518910ea387": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
