{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "661cde4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (2.0.0)\n",
      "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch) (3.12.0)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: jinja2 in /Users/patrickbales/Library/Python/3.9/lib/python/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/patrickbales/Library/Python/3.9/lib/python/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: torchvision in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (0.15.1)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torchvision) (2.29.0)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torchvision) (9.5.0)\n",
      "Requirement already satisfied: torch==2.0.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torchvision) (2.0.0)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch==2.0.0->torchvision) (3.1)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch==2.0.0->torchvision) (1.11.1)\n",
      "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch==2.0.0->torchvision) (4.5.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch==2.0.0->torchvision) (3.12.0)\n",
      "Requirement already satisfied: jinja2 in /Users/patrickbales/Library/Python/3.9/lib/python/site-packages (from torch==2.0.0->torchvision) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/patrickbales/Library/Python/3.9/lib/python/site-packages (from jinja2->torch==2.0.0->torchvision) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/patrickbales/Library/Python/3.9/lib/python/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->torchvision) (3.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->torchvision) (1.26.15)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from sympy->torch==2.0.0->torchvision) (1.3.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (1.24.3)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (3.7.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/patrickbales/Library/Python/3.9/lib/python/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from matplotlib) (5.12.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from matplotlib) (1.24.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from matplotlib) (4.39.3)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/patrickbales/Library/Python/3.9/lib/python/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from matplotlib) (9.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/patrickbales/Library/Python/3.9/lib/python/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from matplotlib) (1.0.7)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/patrickbales/Library/Python/3.9/lib/python/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.10.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/patrickbales/Library/Python/3.9/lib/python/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install torch\n",
    "!{sys.executable} -m pip install torchvision\n",
    "!{sys.executable} -m pip install numpy\n",
    "!{sys.executable} -m pip install matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import copy\n",
    "\n",
    "#import warnings\n",
    "#warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f796aee",
   "metadata": {},
   "source": [
    "Detect if GPU available, otherwise use CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f282b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bab4c9a3",
   "metadata": {},
   "source": [
    "Load MNIST dataset of $28 \\times 28$ images. Training does NOT use the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "051e4c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='../data', train=True, download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='../data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87eea90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    '''\n",
    "    Visualizes IMG.\n",
    "    IMG should be a 2D torch Tensor.\n",
    "    '''\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.detach().numpy()\n",
    "    plt.imshow(npimg, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y3oepvCSLyfi"
   },
   "source": [
    "# Primal Network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "98adced1",
   "metadata": {},
   "source": [
    "This is the definition of the neural classifier for a custom number of layers (depth) and width. The first layer still has $28 \\times 28$ features, and the output layer still has ten output classes (0-9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9cb6c3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "  \n",
    "  #Constructor with default NN width = 256 and default NN depth = 3\n",
    "  def __init__(self, width=256, depth=3):\n",
    "    super().__init__()\n",
    "    self.layers = nn.ModuleList()\n",
    "    self.width = width\n",
    "    self.depth = depth\n",
    "    for w in range(0, depth - 1):\n",
    "      if w == 0:\n",
    "        self.layers.append(nn.Linear(in_features = 28*28, out_features = width))\n",
    "      elif w == depth - 2:\n",
    "        self.layers.append(nn.Linear(in_features = width, out_features = 10))    \n",
    "      else:\n",
    "        self.layers.append(nn.Linear(in_features = width, out_features = width))\n",
    "  \n",
    "  \n",
    "  def forward(self, t):\n",
    "    '''\n",
    "    On input T, performs a affine transformation, then\n",
    "    a ReLU, then another affine transformation.\n",
    "    '''\n",
    "    self.z = []\n",
    "    t = t.reshape(-1, 28*28)\n",
    "    for i in range(0, self.depth - 1):\n",
    "      t = self.layers[i](t)\n",
    "      self.z.append(t)\n",
    "      if i != self.depth - 2:\n",
    "        t = F.relu(t)\n",
    "    return t"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "62d149ab",
   "metadata": {},
   "source": [
    "Provided training code using Adam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e70c44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, criterion, trainloader, depth, lr=0.001):\n",
    "    '''\n",
    "    Uses the Adam optimization algorithm to train \n",
    "    the classifier NET on training data from TRAINLOADER,\n",
    "    on loss function CRITERION, with learning rate LR.\n",
    "    \n",
    "    Note that we half the learning rate each epoch.\n",
    "    '''\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(depth):\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr * 0.5 ** (epoch)\n",
    "\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            if i % 500 == 0:\n",
    "                print('Epoch', epoch, 'Iter:', i, 'Loss', loss.item())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e43d9cc3",
   "metadata": {},
   "source": [
    "Train the network using cross entropy loss. Note that this is equivalent to maximizing the KL-divergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea0df5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Iter: 0 Loss 2.3271470069885254\n",
      "Epoch 0 Iter: 500 Loss 0.7162825465202332\n",
      "Epoch 0 Iter: 1000 Loss 0.199073925614357\n",
      "Epoch 0 Iter: 1500 Loss 1.7676581144332886\n",
      "Epoch 0 Iter: 2000 Loss 0.4789253771305084\n",
      "Epoch 0 Iter: 2500 Loss 0.11749890446662903\n",
      "Epoch 0 Iter: 3000 Loss 0.006040720734745264\n",
      "Epoch 0 Iter: 3500 Loss 1.0255928039550781\n",
      "Epoch 0 Iter: 4000 Loss 0.2310912162065506\n",
      "Epoch 0 Iter: 4500 Loss 0.3562363088130951\n",
      "Epoch 0 Iter: 5000 Loss 0.007588902022689581\n",
      "Epoch 0 Iter: 5500 Loss 0.2427343875169754\n",
      "Epoch 0 Iter: 6000 Loss 0.007677924819290638\n",
      "Epoch 0 Iter: 6500 Loss 1.3296210765838623\n",
      "Epoch 0 Iter: 7000 Loss 0.0011598150013014674\n",
      "Epoch 0 Iter: 7500 Loss 0.013396050781011581\n",
      "Epoch 0 Iter: 8000 Loss 0.08768776059150696\n",
      "Epoch 0 Iter: 8500 Loss 0.631874144077301\n",
      "Epoch 0 Iter: 9000 Loss 0.6030470728874207\n",
      "Epoch 0 Iter: 9500 Loss 0.100438192486763\n",
      "Epoch 0 Iter: 10000 Loss 0.03144074231386185\n",
      "Epoch 0 Iter: 10500 Loss 0.038854289799928665\n",
      "Epoch 0 Iter: 11000 Loss 0.03606705367565155\n",
      "Epoch 0 Iter: 11500 Loss 0.0244741253554821\n",
      "Epoch 0 Iter: 12000 Loss 0.5567772388458252\n",
      "Epoch 0 Iter: 12500 Loss 0.26008906960487366\n",
      "Epoch 0 Iter: 13000 Loss 0.8663480877876282\n",
      "Epoch 0 Iter: 13500 Loss 0.4994509518146515\n",
      "Epoch 0 Iter: 14000 Loss 0.05451415106654167\n",
      "Epoch 0 Iter: 14500 Loss 0.030564455315470695\n",
      "Epoch 1 Iter: 0 Loss 0.02163263037800789\n",
      "Epoch 1 Iter: 500 Loss 0.0007241143030114472\n",
      "Epoch 1 Iter: 1000 Loss 0.5525983572006226\n",
      "Epoch 1 Iter: 1500 Loss 1.6564356088638306\n",
      "Epoch 1 Iter: 2000 Loss 0.23031531274318695\n",
      "Epoch 1 Iter: 2500 Loss 0.003081747330725193\n",
      "Epoch 1 Iter: 3000 Loss 2.56961989402771\n",
      "Epoch 1 Iter: 3500 Loss 0.2143714278936386\n",
      "Epoch 1 Iter: 4000 Loss 0.3892623484134674\n",
      "Epoch 1 Iter: 4500 Loss 0.02063046582043171\n",
      "Epoch 1 Iter: 5000 Loss 0.01832934468984604\n",
      "Epoch 1 Iter: 5500 Loss 1.2240020036697388\n",
      "Epoch 1 Iter: 6000 Loss 0.0006113351555541158\n",
      "Epoch 1 Iter: 6500 Loss 0.007184160407632589\n",
      "Epoch 1 Iter: 7000 Loss 0.13427291810512543\n",
      "Epoch 1 Iter: 7500 Loss 0.029867950826883316\n",
      "Epoch 1 Iter: 8000 Loss 0.035905420780181885\n",
      "Epoch 1 Iter: 8500 Loss 0.005214123986661434\n",
      "Epoch 1 Iter: 9000 Loss 0.22119997441768646\n",
      "Epoch 1 Iter: 9500 Loss 0.007833129726350307\n",
      "Epoch 1 Iter: 10000 Loss 1.645040902076289e-05\n",
      "Epoch 1 Iter: 10500 Loss 0.004981471225619316\n",
      "Epoch 1 Iter: 11000 Loss 0.007144509349018335\n",
      "Epoch 1 Iter: 11500 Loss 0.0981031283736229\n",
      "Epoch 1 Iter: 12000 Loss 0.17478100955486298\n",
      "Epoch 1 Iter: 12500 Loss 0.10238981246948242\n",
      "Epoch 1 Iter: 13000 Loss 0.0010570008307695389\n",
      "Epoch 1 Iter: 13500 Loss 0.21883787214756012\n",
      "Epoch 1 Iter: 14000 Loss 0.01849745400249958\n",
      "Epoch 1 Iter: 14500 Loss 0.00014675833517685533\n",
      "Epoch 2 Iter: 0 Loss 0.0064865401946008205\n",
      "Epoch 2 Iter: 500 Loss 0.0001560916134621948\n",
      "Epoch 2 Iter: 1000 Loss 0.0025175518821924925\n",
      "Epoch 2 Iter: 1500 Loss 0.0003322760749142617\n",
      "Epoch 2 Iter: 2000 Loss 0.0001933856401592493\n",
      "Epoch 2 Iter: 2500 Loss 0.001508475048467517\n",
      "Epoch 2 Iter: 3000 Loss 0.04892034828662872\n",
      "Epoch 2 Iter: 3500 Loss 1.2069774129486177e-05\n",
      "Epoch 2 Iter: 4000 Loss 0.01957688294351101\n",
      "Epoch 2 Iter: 4500 Loss 0.02923576533794403\n",
      "Epoch 2 Iter: 5000 Loss 0.005612657871097326\n",
      "Epoch 2 Iter: 5500 Loss 0.030864858999848366\n",
      "Epoch 2 Iter: 6000 Loss 0.02126859314739704\n",
      "Epoch 2 Iter: 6500 Loss 0.4678427577018738\n",
      "Epoch 2 Iter: 7000 Loss 0.042583297938108444\n",
      "Epoch 2 Iter: 7500 Loss 0.01603849232196808\n",
      "Epoch 2 Iter: 8000 Loss 0.006703837309032679\n",
      "Epoch 2 Iter: 8500 Loss 0.009616322815418243\n",
      "Epoch 2 Iter: 9000 Loss 0.10385245829820633\n",
      "Epoch 2 Iter: 9500 Loss 0.0002698359894566238\n",
      "Epoch 2 Iter: 10000 Loss 0.008032006211578846\n",
      "Epoch 2 Iter: 10500 Loss 0.0026996242813766003\n",
      "Epoch 2 Iter: 11000 Loss 0.0014575649984180927\n",
      "Epoch 2 Iter: 11500 Loss 8.075683581409976e-05\n",
      "Epoch 2 Iter: 12000 Loss 0.010189901106059551\n",
      "Epoch 2 Iter: 12500 Loss 0.0003522720653563738\n",
      "Epoch 2 Iter: 13000 Loss 0.004143417347222567\n",
      "Epoch 2 Iter: 13500 Loss 0.023804573342204094\n",
      "Epoch 2 Iter: 14000 Loss 0.2963077425956726\n",
      "Epoch 2 Iter: 14500 Loss 0.0368502214550972\n",
      "Epoch 3 Iter: 0 Loss 0.0006648409180343151\n",
      "Epoch 3 Iter: 500 Loss 0.03971310704946518\n",
      "Epoch 3 Iter: 1000 Loss 0.0007745241746306419\n",
      "Epoch 3 Iter: 1500 Loss 0.002617794321849942\n",
      "Epoch 3 Iter: 2000 Loss 8.940695295223122e-08\n",
      "Epoch 3 Iter: 2500 Loss 0.0005565107567235827\n",
      "Epoch 3 Iter: 3000 Loss 0.0011541813146322966\n",
      "Epoch 3 Iter: 3500 Loss 0.0015035666292533278\n",
      "Epoch 3 Iter: 4000 Loss 0.002223965944722295\n",
      "Epoch 3 Iter: 4500 Loss 0.031893424689769745\n",
      "Epoch 3 Iter: 5000 Loss 0.017419125884771347\n",
      "Epoch 3 Iter: 5500 Loss 0.014078476466238499\n",
      "Epoch 3 Iter: 6000 Loss 5.5431905821023975e-06\n",
      "Epoch 3 Iter: 6500 Loss 0.23499798774719238\n",
      "Epoch 3 Iter: 7000 Loss 1.1920927533992653e-07\n",
      "Epoch 3 Iter: 7500 Loss 0.0\n",
      "Epoch 3 Iter: 8000 Loss 0.9596704244613647\n",
      "Epoch 3 Iter: 8500 Loss 0.17763936519622803\n",
      "Epoch 3 Iter: 9000 Loss 0.0015480645233765244\n",
      "Epoch 3 Iter: 9500 Loss 7.2716607064649e-06\n",
      "Epoch 3 Iter: 10000 Loss 1.046043871610891e-05\n",
      "Epoch 3 Iter: 10500 Loss 0.026171842589974403\n",
      "Epoch 3 Iter: 11000 Loss 0.0002676087897270918\n",
      "Epoch 3 Iter: 11500 Loss 0.226211279630661\n",
      "Epoch 3 Iter: 12000 Loss 0.00288658426143229\n",
      "Epoch 3 Iter: 12500 Loss 2.6731253456091508e-05\n",
      "Epoch 3 Iter: 13000 Loss 0.003286220133304596\n",
      "Epoch 3 Iter: 13500 Loss 0.0005886119906790555\n",
      "Epoch 3 Iter: 14000 Loss 0.22989264130592346\n",
      "Epoch 3 Iter: 14500 Loss 2.196335481130518e-05\n",
      "Epoch 4 Iter: 0 Loss 0.0009913778631016612\n",
      "Epoch 4 Iter: 500 Loss 0.009539210237562656\n",
      "Epoch 4 Iter: 1000 Loss 0.8158864378929138\n",
      "Epoch 4 Iter: 1500 Loss 0.0010070501593872905\n",
      "Epoch 4 Iter: 2000 Loss 9.201377542922273e-05\n",
      "Epoch 4 Iter: 2500 Loss 0.0004270901554264128\n",
      "Epoch 4 Iter: 3000 Loss 0.6215620040893555\n",
      "Epoch 4 Iter: 3500 Loss 0.0005714832223020494\n",
      "Epoch 4 Iter: 4000 Loss 0.08716662228107452\n",
      "Epoch 4 Iter: 4500 Loss 0.1635035276412964\n",
      "Epoch 4 Iter: 5000 Loss 0.0003864163882099092\n",
      "Epoch 4 Iter: 5500 Loss 0.00023833474551793188\n",
      "Epoch 4 Iter: 6000 Loss 0.0003116221632808447\n",
      "Epoch 4 Iter: 6500 Loss 0.021748468279838562\n",
      "Epoch 4 Iter: 7000 Loss 0.005270769819617271\n",
      "Epoch 4 Iter: 7500 Loss 0.007310468703508377\n",
      "Epoch 4 Iter: 8000 Loss 0.00031061586923897266\n",
      "Epoch 4 Iter: 8500 Loss 6.761670374544337e-05\n",
      "Epoch 4 Iter: 9000 Loss 0.0018867587205022573\n",
      "Epoch 4 Iter: 9500 Loss 7.026423554634675e-05\n",
      "Epoch 4 Iter: 10000 Loss 3.561132325557992e-05\n",
      "Epoch 4 Iter: 10500 Loss 0.07952220737934113\n",
      "Epoch 4 Iter: 11000 Loss 0.0034628724679350853\n",
      "Epoch 4 Iter: 11500 Loss 0.00018519100558478385\n",
      "Epoch 4 Iter: 12000 Loss 0.0006582150817848742\n",
      "Epoch 4 Iter: 12500 Loss 0.012248787097632885\n",
      "Epoch 4 Iter: 13000 Loss 2.0861619987044833e-07\n",
      "Epoch 4 Iter: 13500 Loss 0.23332840204238892\n",
      "Epoch 4 Iter: 14000 Loss 0.00015617535973433405\n",
      "Epoch 4 Iter: 14500 Loss 0.0012430291390046477\n"
     ]
    }
   ],
   "source": [
    "net = Net(depth=5)\n",
    "net.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train(net, criterion, trainloader, net.depth, 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049684da",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7a3a2618",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter = iter(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cd97fc13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier output: tensor([[-20.6649, -27.7976, -18.7386, -13.5673,  -6.0387, -13.6367, -35.5705,\n",
      "         -10.2093, -19.5934,   3.9606]])\n",
      "Classifier prediction: 9\n"
     ]
    }
   ],
   "source": [
    "x, labels = next(test_iter)\n",
    "x = x[0].unsqueeze(0)\n",
    "labels = labels[0].unsqueeze(0)\n",
    "imshow(x[0,0])\n",
    "\n",
    "x = x.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "out = net(x).data\n",
    "print('Classifier output:', out)\n",
    "print('Classifier prediction:', torch.argmax(out).item())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d65bfa74",
   "metadata": {},
   "source": [
    "Lorem ipsum..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d926ff3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
